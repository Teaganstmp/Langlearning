{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Teaganstmp/Langlearning/blob/main/dictionaries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_3mAxmot2Z2"
      },
      "source": [
        "# Python dictionaries: Mapping keys to values\n",
        "\n",
        "In our initial example of \"how do I count how often each word appears in a newspaper article\", the central data structure was a \"sheet of counts\": For each word, we kept a sequence of dashes indicating how often we had seen that word.\n",
        "\n",
        "In this notebook you will learn how to use Python dictionaries for multiple purposes.\n",
        "* You'll learn how to store \"sheets of counts\", for example of frequent words in a text.\n",
        "* More generally, you can view a dictionary as a flexible-sized collection of variables (containers). We'll discuss how that is useful.\n",
        "* We'll also discuss how to use Python dictionaries to store an attribute-value matrix or feature structure (something like this: https://en.wikipedia.org/wiki/Feature_structure)\n",
        "\n",
        "Here's how it works technically. Image a dictionary, say, a translation dictionary from English to German. To look up how to say \"cat\" in German, you would look under \"cat\", and you would find \"Katze\". To retrieve a piece of information, namely \"Katze\", you look it up under a particular *key*, here its word in English. This is also\n",
        "\n",
        "need to know where in the dictionary to find it: You can find it under 'cat'.  -- by looking it up\n",
        "\n",
        "In the \"sheet of counts\", we *connected* each word to a count (a sequence of dashes). We *mapped* each word to a count. This is what a Python dictionary does: It stores *values* under particular *keys*, it connects each key to a value, so that you can retrieve the value using the key. This is also what a Python dictionary does: It stores each *value* under a *key*, so that you can use the key to look up the value.\n",
        "\n",
        "Here is what a Python dictionary for an English-to-German dictionary could look like:\n",
        "```\n",
        "{\n",
        "\"dog\" : \"Hund\",\n",
        "\"cat\" : \"Katze\",\n",
        "\"rhino\" : \"Nashorn\"\n",
        "}\n",
        "```\n",
        "\n",
        "It contains pairs of data, connected by a \":\". In each pair, the left entry (e.g., \"dog\") is the key, and the right entry (e.g., \"Hund\") is the value.\n",
        "\n",
        "You can use the same structure, of key:value pairs, to store a \"sheet of counts\". Here is what that could look like as a Python dictionary:\n",
        "\n",
        "\n",
        "```\n",
        "{\n",
        "\"the\" : 3,\n",
        "\"recent\" : 1,\n",
        "\"development\" : 1,\n",
        "\"that\" : 2\n",
        "}\n",
        "```\n",
        "\n",
        "This says that we have three counts of \"the\", one count of \"recent\", and so on.\n",
        "\n",
        "In the second case, the keys were strings, and the values were also strings. In the second case, the keys were again strings, and the values were numbers. Dictionaries are flexible about this. (And the keys could be numbers, or other data types.)\n",
        "\n",
        "Here is how to construct a Python dictionary from scratch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUqQA_aWt2Z4",
        "outputId": "b15c2cfb-858e-45c5-92ec-93b6a9f82564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result of dictionary making: {'dog': 'canis', 'cat': 'felis', 'rhino': 'rhinoceros', 'mouse': 'mus'}\n"
          ]
        }
      ],
      "source": [
        "latindict = { \"dog\": \"canis\", \"cat\":\"felis\", \"rhino\": \"rhinoceros\",\n",
        "            \"mouse\": \"mus\"}\n",
        "\n",
        "print(\"result of dictionary making:\", latindict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxgGRgkBt2Z5"
      },
      "source": [
        "Or you can start with an empty dictionary and fill it one step at a time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH5i2cFZt2Z5",
        "outputId": "4b66043d-bca4-4683-f9cb-2c6e4d37ff44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1 mydict is {}\n",
            "Step 2 mydict is {'dog': 'Hund'}\n",
            "Step 3 mydict is {'dog': 'Hund', 'cat': 'Katze'}\n",
            "Step 4 mydict is {'dog': 'Hund', 'cat': 'Katze', 'rhino': 'Nashorn'}\n"
          ]
        }
      ],
      "source": [
        "germandict = {}\n",
        "print(\"Step 1 mydict is\", germandict)\n",
        "\n",
        "germandict[\"dog\"] = \"Hund\"\n",
        "print(\"Step 2 mydict is\", germandict)\n",
        "\n",
        "germandict[\"cat\"] = \"Katze\"\n",
        "print(\"Step 3 mydict is\", germandict)\n",
        "\n",
        "germandict[\"rhino\"] = \"Nashorn\"\n",
        "print(\"Step 4 mydict is\", germandict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p15JylEZt2Z6"
      },
      "source": [
        "Here is how you can access a dictionary. Give the key to get the corresponding value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "sXQ4zAeat2Z7",
        "outputId": "24f2b1cd-e609-4541-b683-bfc15d6c5674"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hund'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "germandict[\"dog\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "foenMXSkt2Z8",
        "outputId": "7efd9e87-a98c-49c8-bad0-0f132863a583"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mus'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "latindict[\"mouse\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH2AaYspt2Z9"
      },
      "source": [
        "Note that when you make a new dictionary, you need to use curly brackets, as in:\n",
        "\n",
        "```germandict = { }```\n",
        "\n",
        "But when you access the dictionary, or when you add a single entry to a dictionary, you use straight brackets, as in:\n",
        "\n",
        "```latindict[\"mouse\"]```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjfia4ZEt2Z9"
      },
      "source": [
        "## Comparing Python dictionaries and Python lists\n",
        "\n",
        "Let's compare notation across dictionaries and lists.\n",
        "\n",
        "Initializing to an empty data structure:\n",
        "```\n",
        "mylist = []       # empty list: straight brackets\n",
        "mydict = {}    # empty dictionary: curly brackets\n",
        "```\n",
        "\n",
        "Initializing to a nonempty data structure:\n",
        "```\n",
        "# initializing a list:straight brackets\n",
        "mylist = [“dog”, “cat”, “rhinoceros”]\n",
        "# initializing a dictionary: curly brackets, key-colon-value\n",
        "mydict = {\"dog\":\"Hund\", \"cat\":\"Katze\",  \"rhinoceros\":\"Nashorn\"}\n",
        "```\n",
        "\n",
        "Accessing items on a list: index in straight brackets. A list “maps” indices to items.\n",
        "\n",
        "```\n",
        "mylist[1]  ### will yield 'cat'\n",
        "```\n",
        "\n",
        "Accessing items on a dictionary: key in straight brackets. A dictionary maps keys to values.\n",
        "\n",
        "```\n",
        "mydict['cat'] ### will yield 'Katze'\n",
        "```\n",
        "\n",
        "The standard way to modify a list is via ```append()```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo4-wOWtt2Z9",
        "outputId": "957d29f7-953b-439d-fe14-9ce4802cc120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "changed list ['dog', 'cat', 'rhinoceros', 'armadillo']\n"
          ]
        }
      ],
      "source": [
        "mylist = [\"dog\", \"cat\", \"rhinoceros\"]\n",
        "mylist.append(\"armadillo\")\n",
        "print(\"changed list\", mylist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb75R4x3t2Z-"
      },
      "source": [
        "The standard way to modify a dictionary is to store a value under a key. If you had a key/value pair before and change the value, the previous value is gone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwRwn68Rt2Z-",
        "outputId": "9496b793-cbf8-49e4-e461-225a823a32b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original dictionary {'dog': 'Hund', 'cat': 'Katze'}\n",
            "dictionary after adding an item {'dog': 'Hund', 'cat': 'Katze', 'armadillo': 'Guerteltier'}\n",
            "dictionary after changing the value {'dog': 'Hund', 'cat': 'felis', 'armadillo': 'Guerteltier'}\n"
          ]
        }
      ],
      "source": [
        "mydict = {\"dog\":\"Hund\", \"cat\":\"Katze\"}\n",
        "print(\"original dictionary\", mydict)\n",
        "\n",
        "# adding an item\n",
        "# (the German word for 'armadillo' means literally belt-animal)\n",
        "mydict[\"armadillo\"] = \"Guerteltier\"\n",
        "print(\"dictionary after adding an item\", mydict)\n",
        "\n",
        "# changing a value.\n",
        "# the previous value is gone.\n",
        "mydict[\"cat\"] = \"felis\"\n",
        "print(\"dictionary after changing the value\", mydict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgzJKg3tt2Z_"
      },
      "source": [
        "In a list, you get an error when you try to access a list index that isn't there. In the same way, in a dictionary, you get an error when you try to access a key that isn't there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFo6K3YTt2Z_"
      },
      "outputs": [],
      "source": [
        "mylist = [\"dog\", \"cat\", \"rhinoceros\"]\n",
        "# remove the hash in the beginning of the 'print' line\n",
        "# that is, \"uncomment\" the 'print' line,\n",
        "# to get an IndexError.\n",
        "# print(\"this will get you an error\", mylist[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDn-T3ujt2aA"
      },
      "outputs": [],
      "source": [
        "mydict = {'dog':'Hund', 'rhinoceros':'Nashorn'}\n",
        "# remove the hash in the beginning of the 'print' line\n",
        "# that is, \"uncomment\" the 'print' line,\n",
        "# to get a KeyError.\n",
        "# print('this will get you an error', mydict['cat'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzlcN8fbt2aA"
      },
      "source": [
        "## Dictionary keys and dictionary values\n",
        "\n",
        "**What can be a dictionary key?**\n",
        "\n",
        "Strings can be dictionary keys:\n",
        "```mydict = {\"dog\":\"Hund\", \"rhinoceros\":\"Nashorn\"}```\n",
        "\n",
        "Integers can be dictionary keys, for example:\n",
        "\n",
        "```prime_nums = {2:1, 3:2, 5:3, 7:4, 11:5}```\n",
        "\n",
        "\n",
        "Not everything can be a dictionary key, for example lists cannot. It's because lists are *mutable*, that is, you can change a list in place. That's not good for a key: It's like a key made of playdough that you can reshape -- but after you reshaped it, it's not going to fit into the lock anymore. So Python disallows it.\n",
        "\n",
        "**What can be a dictionary value?**\n",
        "\n",
        "Any data type can be a dictionary value. Even a dictionary can be a dictionary value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "UKTw_YjTt2aA"
      },
      "source": [
        "## Checking whether a key is present\n",
        "\n",
        "You can use ```in``` to check whether a key is in a dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsI-y4-nt2aB",
        "outputId": "076ca454-42c5-482b-8d88-05c130b14c02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is 'mouse' present? False\n",
            "is 'armadillo' present? True\n"
          ]
        }
      ],
      "source": [
        "mydict = {\"dog\":\"Hund\", \"cat\":\"Katze\", \"armadillo\":\"Guerteltier\"}\n",
        "print(\"is 'mouse' present?\", 'mouse' in mydict)\n",
        "print(\"is 'armadillo' present?\", \"armadillo\" in mydict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuAECyMrt2aB"
      },
      "source": [
        "The Boolean expression with ```in``` checks keys, it does not check values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMvhXhRMt2aB",
        "outputId": "84c1b4ee-3482-4a49-ae85-4be076a5059f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "mydict = {\"dog\":\"Hund\", \"cat\":\"Katze\", \"armadillo\":\"Guerteltier\"}\n",
        "'Katze' in mydict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z-HkP4qt2aB"
      },
      "source": [
        "If you try to access a key that isn't there, you get a Key Error. Uncomment the following piece of code to see one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "dW7_faXGt2aB"
      },
      "outputs": [],
      "source": [
        "# mydict = {\"dog\":\"Hund\", \"cat\":\"Katze\", \"armadillo\":\"Guerteltier\"}\n",
        "# mydict[\"dormouse\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo9JoELYt2aB"
      },
      "source": [
        "Having to constantly check whether a key is in the dictionary can be annoying, especially when you populate a large dictionary in a loop. There is a Python data structure that fixes the problem, a `defaultdict` from the package `collections` (https://docs.python.org/3/library/collections.html). We'll see it in use below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyvaOmVpt2aC"
      },
      "source": [
        "**Try it for yourself**\n",
        "\n",
        "* Say we have the following dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzvIzrqJt2aC"
      },
      "outputs": [],
      "source": [
        "dict1 = { \"dog\" : \"Hund\", \"armadillo\" : \"Guerteltier\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvz4MLULt2aC"
      },
      "source": [
        "Please add to this dictionary the translation of platypus, which is Schnabeltier (literally, beak animal)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlSUrAZmt2aC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVfN6oh8t2aC"
      },
      "source": [
        "* Say we have the following dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dd4rP5St2aD"
      },
      "outputs": [],
      "source": [
        "dict2 = { \"the\" : 1, \"a\" : 2}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDbNj8nit2aD"
      },
      "source": [
        "Please change the entry for \"the\" to be two instead of one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE9IUKrIt2aD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7_DEPrnt2aD"
      },
      "source": [
        "Here is a piece of code that gives you an example of how to do the next \"Try it for yourself\" below. It iterates over a list of function words, using each of them as a key to retrieve the matching value from the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSCQf96bt2aD",
        "outputId": "19eb38f3-d3ea-4ca2-b423-1d1998e88b25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "function word counts\n",
            "the 21\n",
            "and 3\n",
            "a 15\n"
          ]
        }
      ],
      "source": [
        "mylist = [ \"the\", \"and\", \"a\"]\n",
        "dictionary_of_counts = { \"house\" : 2, \"armadillo\" : 1,\n",
        "                         \"the\" : 21, \"recent\" : 2,\n",
        "                         \"said\": 3, \"a\" : 15,\n",
        "                         \"went\": 2, \"and\": 3,\n",
        "                         \"yellow\": 1}\n",
        "print(\"function word counts\")\n",
        "for word in mylist:\n",
        "    print(word, dictionary_of_counts[word])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4J7BANmt2aD"
      },
      "source": [
        "**Try it for yourself**\n",
        "\n",
        "Here is a mini German/English dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnILSNcet2aE"
      },
      "outputs": [],
      "source": [
        "mydict = {\"befreit\":\"liberated\", \"baeche\":\"brooks\",\n",
        "          \"eise\":\"ice\", \"sind\":\"are\", \"strom\":\"river\",\n",
        "          \"und\":\"and\", \"vom\":\"from\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzCojgC9t2aE"
      },
      "source": [
        "Can you use this dictionary to do a bad translation of the following German sentence? (Hint: this should look a lot like the use case above\n",
        "where we iterated over a list and printed out dictionary values\n",
        "for items on the list.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMfnIPmVt2aE"
      },
      "outputs": [],
      "source": [
        "mysent = \"vom eise befreit sind strom und baeche\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pahrHPmRt2aE"
      },
      "source": [
        "*Warning:* Solution below, don't read on if you want to solve the \"bad translation\" problem for youself.\n",
        "\n",
        "...\n",
        "\n",
        "...\n",
        "\n",
        "...\n",
        "\n",
        "...\n",
        "\n",
        "...\n",
        "\n",
        "...\n",
        "\n",
        "...\n",
        "\n",
        "...\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Here is a solution.(Note that this is not how you want your machine translation to work! The translations that you get this way are terrible.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYBxho4Jt2aE",
        "outputId": "da528b1b-2bf6-4a3e-9bc9-c5a5eaa8d360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from ice liberated are river and brooks \n"
          ]
        }
      ],
      "source": [
        "mydict = {\"befreit\":\"liberated\", \"baeche\":\"brooks\", \"eise\":\"ice\", \"sind\":\"are\", \"strom\":\"river\", \"und\":\"and\", \"vom\":\"from\"}\n",
        "mysent = \"vom eise befreit sind strom und baeche\"\n",
        "for german_word in mysent.split():\n",
        "    print( mydict[ german_word], end = \" \")\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIQvAl1_t2aE"
      },
      "source": [
        "Adding the parameter ```end = \" \"``` puts a space instead of a linebreak at the end of what is printed. That way, multiple \"print\" outputs land on the same line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcsqmcXvt2aF"
      },
      "source": [
        "# A dictionary as a collection of variables/containers\n",
        "\n",
        "In a way, you can view a dictionary as a collection of containers, each of which you address by the key.\n",
        "\n",
        "First, let's see what happens when we have individual variables. Here's a variable storing the translation of \"platypus\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "Hh82E--St2aF",
        "outputId": "5646d2e4-2fd3-4240-8142-4f9468133fe0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Schnabeltier'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "platypus_translation = \"Schnabeltier\"\n",
        "platypus_translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCUYcW8rt2aF"
      },
      "source": [
        "And of \"cat\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "TkufIkkQt2aF",
        "outputId": "35cd431f-b487-4b56-a66b-e075f8f2073c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Katze'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "cat_translation = \"Katze\"\n",
        "cat_translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOIr2f0ut2aF"
      },
      "source": [
        "We can make more of these, but we need to know, ahead of time, how many translations we want to store. In a dictionary, we can always store as many as we need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "GW9zsdWNt2aF",
        "outputId": "efbc2797-7b8c-4e10-f7a6-ea375be4423b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Schnabeltier'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "mydict = {\"cat\":\"Katze\", \"platypus\":\"Schnabeltier\"}\n",
        "mydict[\"platypus\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--mwoAert2aG"
      },
      "source": [
        "Adding an entry:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzV54cdtt2aG",
        "outputId": "65b55cb6-1c4e-4567-e2e7-88edce43f870"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cat': 'Katze', 'platypus': 'Schnabeltier', 'armadillo': 'Guerteltier'}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "mydict[\"armadillo\"] = \"Guerteltier\"\n",
        "mydict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spymeEcjt2aG"
      },
      "source": [
        "Like with individual variables, you can update the value that goes with a key. Here is an example. Say you want to count occurrences of words, and you've seen one more \"the\". Then you record it like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxtLSffXt2aG",
        "outputId": "09d7927e-4a14-4bd8-b64b-d34ca3a606ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 2, 'and': 1, 'of': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "mydict = {\"the\":1, \"and\": 1, \"of\": 1}\n",
        "mydict[\"the\"] = mydict[\"the\"] + 1\n",
        "mydict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAMXQj7ft2aH"
      },
      "source": [
        "Compare this to how you would change the contents of an individual variable/container:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Uo-4rkLt2aH",
        "outputId": "3bec792a-6ede-487f-bd2e-966e7c406603"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "counter = 0\n",
        "mylist = [\"a\", \"b\", 'a']\n",
        "for item in mylist:\n",
        "    if item == \"a\":\n",
        "        counter = counter + 1\n",
        "\n",
        "counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlBJXaJat2aH"
      },
      "source": [
        "## Counting words in a text\n",
        "\n",
        "We can use this idea of a dictionary as a collection of variables/containers to count occurrences of words in a text.\n",
        "\n",
        "First, as a reminder, here is how you can count occurrences of just one word (here: \"to\") in a text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZkEfXIEt2aH",
        "outputId": "bfa636a9-56ba-41d2-ebc3-804a9293575d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ],
      "source": [
        "# paragraph from the Onion, March 04\n",
        "paragraph = \"\"\"While dieters are accustomed to exercises of will,\n",
        "a new English translation of Germany's most popular diet book\n",
        "takes the concept to a new philosophical level.\n",
        "The Nietzschean diet, which commands its adherents to eat\n",
        "superhuman amounts of whatever they most fear,\n",
        "is developing a strong following in America.\"\"\"\n",
        "\n",
        "count_to = 0\n",
        "for word in paragraph.split():\n",
        "    if word == \"to\":\n",
        "        count_to = count_to + 1\n",
        "\n",
        "print( count_to )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfW85XDmt2aI"
      },
      "source": [
        "Now suppose we want to count occurrences of all words at the same time.\n",
        "Then we can use a Python dictionary as a collection of containers, one for each word. The words are the keys, and their counts as the values. Every time we encounter a word, we add one to its value in the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os_s_9Y5t2aI",
        "outputId": "3fd787de-a448-4d5a-da8d-135eb4aa91de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'While': 1, 'dieters': 1, 'are': 1, 'accustomed': 1, 'to': 3, 'exercises': 1, 'of': 3, 'will,': 1, 'a': 3, 'new': 2, 'English': 1, 'translation': 1, \"Germany's\": 1, 'most': 2, 'popular': 1, 'diet': 1, 'book': 1, 'takes': 1, 'the': 1, 'concept': 1, 'philosophical': 1, 'level.': 1, 'The': 1, 'Nietzschean': 1, 'diet,': 1, 'which': 1, 'commands': 1, 'its': 1, 'adherents': 1, 'eat': 1, 'superhuman': 1, 'amounts': 1, 'whatever': 1, 'they': 1, 'fear,': 1, 'is': 1, 'developing': 1, 'strong': 1, 'following': 1, 'in': 1, 'America.': 1}\n"
          ]
        }
      ],
      "source": [
        "# paragraph from the Onion, March 04\n",
        "paragraph = \"\"\"While dieters are accustomed to exercises of\n",
        "will, a new English translation of Germany's most popular\n",
        "diet book takes the concept to a new philosophical level.\n",
        "The Nietzschean diet, which commands its adherents to eat\n",
        "superhuman amounts of whatever they most fear,\n",
        "is developing a strong following in America.\"\"\"\n",
        "\n",
        "counts = { }\n",
        "\n",
        "for word in paragraph.split():\n",
        "    if  word not in counts:\n",
        "        counts[word] = 1\n",
        "    else:\n",
        "        counts[ word ] = counts[ word ] + 1\n",
        "\n",
        "print( counts )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYCMQC1at2aI"
      },
      "source": [
        "The condition ```if word not in counts``` is true if the content of the variable word is not a key in the dictionary counts.\n",
        "\n",
        "Note that this is a variant of the \"accumulation\" code pattern that you have seen before. We initialize counts to an empty dictionary. Then we iterate over the words in the paragraph, adding numbers to the dictionary as we go along. The first time we encounter a word, we initialize its count to zero. We know we encounter it for the first time because there is no dictionary key for them yet.\n",
        "\n",
        "### Using defaultdict\n",
        "\n",
        "Above I've mentioned that when you iteratively populate a dictionary in a loop, it can be annoying to have to check all the time if a key is in the dictionary. You can see this in the code above:\n",
        "\n",
        "```\n",
        "if  word not in counts:\n",
        "        counts[word] = 1\n",
        "    else:\n",
        "        counts[ word ] = counts[ word ] + 1\n",
        "```\n",
        "\n",
        "That is verbose, and hard to read. Here's where the `defaultdict` from the package `collections` comes in. A defaultdict never gives you a key error. Instead, when you try to access a key that doesn't exist yet, it adds that key to the dictionary then and there. When you have an integer defaultdict, the value that gets added for a new key is the zero. (When you have a list defaultdict, the value that gets added for a new key is an empty list.)\n",
        "\n",
        "Here's how that makes our life easier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54oOu-Q-t2aI",
        "outputId": "6f536bbd-8d72-4c25-ac13-04ece799ecd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'int'>, {'While': 1, 'dieters': 1, 'are': 1, 'accustomed': 1, 'to': 3, 'exercises': 1, 'of': 3, 'will,': 1, 'a': 3, 'new': 2, 'English': 1, 'translation': 1, \"Germany's\": 1, 'most': 2, 'popular': 1, 'diet': 1, 'book': 1, 'takes': 1, 'the': 1, 'concept': 1, 'philosophical': 1, 'level.': 1, 'The': 1, 'Nietzschean': 1, 'diet,': 1, 'which': 1, 'commands': 1, 'its': 1, 'adherents': 1, 'eat': 1, 'superhuman': 1, 'amounts': 1, 'whatever': 1, 'they': 1, 'fear,': 1, 'is': 1, 'developing': 1, 'strong': 1, 'following': 1, 'in': 1, 'America.': 1})\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# paragraph from the Onion, March 04\n",
        "paragraph = \"\"\"While dieters are accustomed to exercises of\n",
        "will, a new English translation of Germany's most popular\n",
        "diet book takes the concept to a new philosophical level.\n",
        "The Nietzschean diet, which commands its adherents to eat\n",
        "superhuman amounts of whatever they most fear,\n",
        "is developing a strong following in America.\"\"\"\n",
        "\n",
        "counts = defaultdict(int)\n",
        "\n",
        "for word in paragraph.split():\n",
        "    counts[ word ] = counts[ word ] + 1\n",
        "\n",
        "print( counts )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2AqbMIpt2aI"
      },
      "source": [
        "Why does this work? Well, say you encounter a new word that's not in the dictionary yet, \"dieters\". Then `counts[\"dieters\"]` accesses the key \"dieters\" that doesn't exist yet. So that key gets added to the dictionary, with a value of zero. Then when you add one to that, you get a count of one -- exactly what you want when you've encountered the word for the first time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp3LTJlHt2aI"
      },
      "source": [
        "**Try it for yourself**:\n",
        "* In the code above, each word is counted \"as is\", which means that \"the\" and \"The\" are counted separately. Modify the code such that it lowercases each word before counting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LDdM5bvt2aI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRJPvKqHt2aI"
      },
      "source": [
        "# Counting words using NLTK\n",
        "\n",
        "Word counting is a task that we often need to do when we analyze texts. It is surprising for how many different analyses this is the first step! And because this is such a frequent task, the Natural Language Toolkit has a specialized type of dictionary just for counting (of words, or of other items).\n",
        "\n",
        "This is a trick you will see often with Python packages: They define specialized data types that come with their own methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBDln9RDt2aI",
        "outputId": "27fb7666-f300-46ed-8ba6-b3f73bb72e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The words are ['``', 'You', 'are', 'old', ',', 'Father', 'William', ',', \"''\", 'the', 'young', 'man', 'said', ',', '``', 'And', 'your', 'hair', 'has', 'become', 'very', 'white', ';', 'And', 'yet', 'you', 'incessantly', 'stand', 'on', 'your', 'head—', 'Do', 'you', 'think', ',', 'at', 'your', 'age', ',', 'it', 'is', 'right', '?', \"''\", '``', 'In', 'my', 'youth', ',', \"''\", 'Father', 'William', 'replied', 'to', 'his', 'son', ',', '``', 'I', 'feared', 'it', 'might', 'injure', 'the', 'brain', ';', 'But', 'now', 'that', 'I', \"'m\", 'perfectly', 'sure', 'I', 'have', 'none', ',', 'Why', ',', 'I', 'do', 'it', 'again', 'and', 'again', '.', \"''\", '``', 'You', 'are', 'old', ',', \"''\", 'said', 'the', 'youth', ',', '``', 'as', 'I', 'mentioned', 'before', ',', 'And', 'have', 'grown', 'most', 'uncommonly', 'fat', ';', 'Yet', 'you', 'turned', 'a', 'back-somersault', 'in', 'at', 'the', 'door—', 'Pray', ',', 'what', 'is', 'the', 'reason', 'of', 'that', '?', \"''\", '``', 'In', 'my', 'youth', ',', \"''\", 'said', 'the', 'sage', ',', 'as', 'he', 'shook', 'his', 'grey', 'locks', ',', '``', 'I', 'kept', 'all', 'my', 'limbs', 'very', 'supple', 'By', 'the', 'use', 'of', 'this', 'ointment—one', 'shilling', 'the', 'box—', 'Allow', 'me', 'to', 'sell', 'you', 'a', 'couple', '.', \"''\", '``', 'You', 'are', 'old', ',', \"''\", 'said', 'the', 'youth', ',', '``', 'and', 'your', 'jaws', 'are', 'too', 'weak', 'For', 'anything', 'tougher', 'than', 'suet', ';', 'Yet', 'you', 'finished', 'the', 'goose', ',', 'with', 'the', 'bones', 'and', 'the', 'beak—', 'Pray', ',', 'how', 'did', 'you', 'manage', 'to', 'do', 'it', '?', \"''\", '``', 'In', 'my', 'youth', ',', \"''\", 'said', 'his', 'father', ',', '``', 'I', 'took', 'to', 'the', 'law', ',', 'And', 'argued', 'each', 'case', 'with', 'my', 'wife', ';', 'And', 'the', 'muscular', 'strength', ',', 'which', 'it', 'gave', 'to', 'my', 'jaw', ',', 'Has', 'lasted', 'the', 'rest', 'of', 'my', 'life', '.', \"''\", '``', 'You', 'are', 'old', ',', \"''\", 'said', 'the', 'youth', ',', '``', 'one', 'would', 'hardly', 'suppose', 'That', 'your', 'eye', 'was', 'as', 'steady', 'as', 'ever', ';', 'Yet', 'you', 'balanced', 'an', 'eel', 'on', 'the', 'end', 'of', 'your', 'nose—', 'What', 'made', 'you', 'so', 'awfully', 'clever', '?', \"''\", '``', 'I', 'have', 'answered', 'three', 'questions', ',', 'and', 'that', 'is', 'enough', ',', \"''\", 'Said', 'his', 'father', ';', '``', 'do', \"n't\", 'give', 'yourself', 'airs', '!', 'Do', 'you', 'think', 'I', 'can', 'listen', 'all', 'day', 'to', 'such', 'stuff', '?', 'Be', 'off', ',', 'or', 'I', \"'ll\", 'kick', 'you', 'down', 'stairs', '!']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "# making sure we can split words\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "# a poem from Alice in Wonderland\n",
        "data = \"\"\"\"You are old, Father William,\" the young man said,\n",
        "    \"And your hair has become very white;\n",
        "And yet you incessantly stand on your head—\n",
        "    Do you think, at your age, it is right?\"\n",
        "\n",
        "\"In my youth,\" Father William replied to his son,\n",
        "    \"I feared it might injure the brain;\n",
        "But now that I'm perfectly sure I have none,\n",
        "    Why, I do it again and again.\"\n",
        "\n",
        "\"You are old,\" said the youth, \"as I mentioned before,\n",
        "    And have grown most uncommonly fat;\n",
        "Yet you turned a back-somersault in at the door—\n",
        "    Pray, what is the reason of that?\"\n",
        "\n",
        "\"In my youth,\" said the sage, as he shook his grey locks,\n",
        "    \"I kept all my limbs very supple\n",
        "By the use of this ointment—one shilling the box—\n",
        "    Allow me to sell you a couple.\"\n",
        "\n",
        "\"You are old,\" said the youth, \"and your jaws are too weak\n",
        "    For anything tougher than suet;\n",
        "Yet you finished the goose, with the bones and the beak—\n",
        "    Pray, how did you manage to do it?\"\n",
        "\n",
        "\"In my youth,\" said his father, \"I took to the law,\n",
        "    And argued each case with my wife;\n",
        "And the muscular strength, which it gave to my jaw,\n",
        "    Has lasted the rest of my life.\"\n",
        "\n",
        "\"You are old,\" said the youth, \"one would hardly suppose\n",
        "    That your eye was as steady as ever;\n",
        "Yet you balanced an eel on the end of your nose—\n",
        "    What made you so awfully clever?\"\n",
        "\n",
        "\"I have answered three questions, and that is enough,\"\n",
        "    Said his father; \"don't give yourself airs!\n",
        "Do you think I can listen all day to such stuff?\n",
        "    Be off, or I'll kick you down stairs!\"\"\"\n",
        "\n",
        "# we use the Natural Language Toolkit to split this poem into words\n",
        "# in a way that also splits off punctuation\n",
        "words = nltk.word_tokenize(data)\n",
        "print(\"The words are\", words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEeqMkdjt2aI",
        "outputId": "e17d376c-9b86-4ea2-8764-47aafc832689"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({',': 30, 'the': 17, '``': 16, \"''\": 15, 'you': 10, 'I': 10, ';': 7, 'my': 7, 'said': 6, 'your': 6, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# Here is the item counting dictionary\n",
        "# You initialize it with the list of items to be counted\n",
        "fd = nltk.FreqDist(words)\n",
        "# When you inspect this, you see\n",
        "# the words with the highest counts first\n",
        "fd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-2dXYwEt2aJ",
        "outputId": "20bc1048-f0cd-4665-8866-f5565f27a8a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 30),\n",
              " ('the', 17),\n",
              " ('``', 16),\n",
              " (\"''\", 15),\n",
              " ('you', 10),\n",
              " ('I', 10),\n",
              " (';', 7),\n",
              " ('my', 7),\n",
              " ('said', 6),\n",
              " ('your', 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# the 10 most common words and their counts\n",
        "fd.most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDwWLOmdt2aJ"
      },
      "source": [
        "We can also get the most frequent words in a tabular format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h9OOhlht2aJ",
        "outputId": "40ec4bb0-e4a6-4db9-d69a-f52225eb0d80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ,  the   ``   ''  you    I    ;   my said your \n",
            "  30   17   16   15   10   10    7    7    6    6 \n"
          ]
        }
      ],
      "source": [
        "fd.tabulate(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1zmPga3t2aJ",
        "outputId": "e852ca0c-bc0a-44fe-f5cd-1b1f2a7631ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# the counts for a particular word:\n",
        "# ask this like you would a dictionary\n",
        "fd[\"youth\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftImdsSPt2aJ"
      },
      "source": [
        "**Try it for yourself**:\n",
        "\n",
        "Get a short text passage from some webpage, and store it as a Python string. Split it into words using either ```split()``` or ```nltk.word_tokenize()```. Then make a new ```nltk.FreqDist``` and use it to count words in the passage.\n",
        "\n",
        "* What are the 5 most frequent words in the passage, and what are their counts?\n",
        "\n",
        "* Is the word \"and\" in the passage? If so, what is its count?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rV865beAt2aJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw5fvFm1t2aK"
      },
      "source": [
        "# All keys, all values, all pairs\n",
        "\n",
        "\n",
        "You can retrieve all the keys of a dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GqjZHa_t2aK",
        "outputId": "924753b6-ea53-486e-b99a-f516fcfa76b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['dog', 'cat', 'armadillo'])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "mydict = {\"dog\":\"Hund\", \"cat\":\"Katze\", \"armadillo\":\"Guerteltier\"}\n",
        "mydict.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5mbyJmQt2aK"
      },
      "source": [
        "What `mydict.keys()` gives you is an iterator -- something that you can iterate over with a for-loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoK6AlTdt2aK",
        "outputId": "20c34c84-ebec-4a12-ebdb-d04ea664eb5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You 4, are 5, old 4, Father 2, William 2, the 17, young 1, man 1, said 6, And 5, your 6, hair 1, has 1, become 1, very 2, white 1, yet 1, you 10, incessantly 1, stand 1, on 2, Do 2, think 2, at 2, age 1, it 5, is 3, right 1, In 3, my 7, youth 6, replied 1, to 6, his 4, son 1, I 10, feared 1, might 1, injure 1, brain 1, But 1, now 1, that 3, perfectly 1, sure 1, have 3, none 1, Why 1, do 3, again 2, and 4, as 4, mentioned 1, before 1, grown 1, most 1, uncommonly 1, fat 1, Yet 3, turned 1, a 2, in 1, Pray 2, what 1, reason 1, of 4, sage 1, he 1, shook 1, grey 1, locks 1, kept 1, all 2, limbs 1, supple 1, By 1, use 1, this 1, shilling 1, Allow 1, me 1, sell 1, couple 1, jaws 1, too 1, weak 1, For 1, anything 1, tougher 1, than 1, suet 1, finished 1, goose 1, with 2, bones 1, how 1, did 1, manage 1, father 2, took 1, law 1, argued 1, each 1, case 1, wife 1, muscular 1, strength 1, which 1, gave 1, jaw 1, Has 1, lasted 1, rest 1, life 1, one 1, would 1, hardly 1, suppose 1, That 1, eye 1, was 1, steady 1, ever 1, balanced 1, an 1, eel 1, end 1, What 1, made 1, so 1, awfully 1, clever 1, answered 1, three 1, questions 1, enough 1, Said 1, give 1, yourself 1, airs 1, can 1, listen 1, day 1, such 1, stuff 1, Be 1, off 1, or 1, kick 1, down 1, stairs 1, "
          ]
        }
      ],
      "source": [
        "# printing counts for all words that\n",
        "# are actual words,\n",
        "# not punctuation\n",
        "for word in fd.keys():\n",
        "    if word.isalpha():\n",
        "        print(word, fd[word], end= \", \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xAM3qMEt2aK"
      },
      "source": [
        "You can also get all the values in a dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5aiqWhDt2aK",
        "outputId": "3f33946e-7e13-43a1-e721-f20be0aa79f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values(['Hund', 'Katze', 'Guerteltier'])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "mydict.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwAWKk_Jt2aK",
        "outputId": "4d306429-eca8-4bcf-c85c-8c2970f77034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hund\n",
            "Katze\n",
            "Guerteltier\n"
          ]
        }
      ],
      "source": [
        "for v in mydict.values():\n",
        "    print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qJearqet2aL",
        "outputId": "379ccba2-c4db-4aac-face-d047e3d0a27e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summed counts in the FreqDist: 354\n",
            "number of words in the poem: 354\n",
            "summed counts in the FreqDist, version 2: 354\n"
          ]
        }
      ],
      "source": [
        "# summing up all the values in the\n",
        "# FreqDist object is\n",
        "# the same as the length of the original poem\n",
        "print(\"summed counts in the FreqDist:\", sum(fd.values()))\n",
        "print(\"number of words in the poem:\", len(nltk.word_tokenize(data)))\n",
        "print(\"summed counts in the FreqDist, version 2:\", fd.N())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIF1RvVJt2aL"
      },
      "source": [
        "**Try it for yourself.**\n",
        "\n",
        "* Above, you made a ```nltk.FreqDist``` object counting words in a passage of your choosing. Now iterate through the keys in that dictionary in order to print counts *only for the uppercase words* in that passage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6QnARSzt2aL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGccELNWt2aL"
      },
      "source": [
        "* Here is a small English/German dictionary as a Python dictionary. Iterate through the values in that dictionary and print only the German words with a length greater or equal to 7 characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI6fS-Hft2aL"
      },
      "outputs": [],
      "source": [
        "translationdict = {\"dog\":\"Hund\", \"cat\": \"Katze\",\n",
        "                   \"dormouse\":\"Siebenschlaefer\",\n",
        "                   \"praying mantis\":\"Gottesanbeterin\",\n",
        "                  \"gopher\" : \"Taschenratte\"}\n",
        "# put code here...\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lWTMRLXt2aL"
      },
      "source": [
        "You can also get access to all key/value pairs in a dictionary, using the method ```items()```:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlu6uo0ot2aL",
        "outputId": "a04e4e40-0176-49d5-a93c-271364819eef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('dog', 'Hund'), ('cat', 'Katze'), ('armadillo', 'Guerteltier')])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "mydict.items()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM2eXRsdt2aL"
      },
      "source": [
        "The items (key/value pairs) have a shape like this:\n",
        "\n",
        "```('dog', 'Hund')```\n",
        "\n",
        "This looks almost like a list, but with round brackets rather than straight, and you can in fact treat it like a list. In particular, you can access the first part of this pair (the key) with index 0, and the second part of the pair (the value) with index 1.\n",
        "\n",
        "This data structure is called a *tuple*. It behaves like a list, except that it is immutable, like a string: you cannot ```append()``` to it, and you cannot exchange individual items on a tuple. So you can actually use it as a dictionary key!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NMhcNo4t2aL",
        "outputId": "54613b06-40f1-4694-88ef-0cc17a9e41e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the first key is dog and the first value is Hund\n"
          ]
        }
      ],
      "source": [
        "firstpair = (\"dog\", \"Hund\")\n",
        "firstkey = firstpair[0]\n",
        "firstvalue = firstpair[1]\n",
        "print(\"the first key is\", firstkey, \"and the first value is\", firstvalue)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-O_3mqHt2aL"
      },
      "source": [
        "Tuples don't have to be length 2. Here is a longer one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "Odv4faeKt2aL",
        "outputId": "8fe5c131-9390-4ee6-c26e-ab9c07b5a64b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "longtuple = (\"a\", \"b\", \"c\", \"d\")\n",
        "longtuple[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVh40p5Wt2aM"
      },
      "source": [
        "You can iterate over the keys of a dictionary, the values of a dictionary, and the key/value pairs (items). Here is how to do the latter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyvRwE2At2aN",
        "outputId": "115ef871-65f1-4f34-81bb-ea4f59751bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English dog translates to German Hund\n",
            "English cat translates to German Katze\n",
            "English armadillo translates to German Guerteltier\n"
          ]
        }
      ],
      "source": [
        "for keyvalue in mydict.items():\n",
        "    english = keyvalue[0]\n",
        "    german = keyvalue[1]\n",
        "    print('English', english, \"translates to German\", german)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tbuGrkWt2aN"
      },
      "source": [
        "You can take a tuple or a list apart by assigning multiple variables to it at once:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCGc_9Jqt2aN",
        "outputId": "f83cadae-788c-4572-c6e0-2689bcefd47c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have assigned dog to 'englishword' and Hund to 'germanword'\n"
          ]
        }
      ],
      "source": [
        "firstpair = (\"dog\", \"Hund\")\n",
        "englishword, germanword = firstpair\n",
        "print(\"We have assigned\", englishword, \"to 'englishword' and\",\n",
        "     germanword, \"to 'germanword'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8IsLCzHt2aN"
      },
      "source": [
        "So you can fill two containers (variables) at the same time by putting them on the left-hand side of the assignment =. That only works if on the right-hand side you have a list or tuple of length exactly two.\n",
        "\n",
        "(You can also assign three/four/... variables at the same time if on the right-hand side you have a list or tuple of length exactly three/four/...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFcc6sSlt2aN",
        "outputId": "7ab9624a-1298-4fce-b8d6-f54e50ed24b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "var1, var2, var3 = (1,2,3)\n",
        "print(var2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek7_LiEGt2aN"
      },
      "source": [
        "Don't miscount, or you get an error message, in particular a ValueError."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yutc1dqmt2aN"
      },
      "outputs": [],
      "source": [
        "# Uncomment (remove the hash from) the 'var1, var2' line\n",
        "# to get a ValueError with comment\n",
        "# \"too many values to unpack (expected 2)\"\n",
        "# var1, var2= (1,2,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpIB0xiJt2aN"
      },
      "source": [
        "Usually when doing assignments, assigning the right-hand side of the \"=\" to the left-hand side, there was only a single variable on the left-hand side. But if we know that the right-hand side of the \"=\" has exactly two components, we can put two variables on the left-hand side. The command above takes the tuple ('rhinoceros', 'Nashorn') apart into two items and assigns the first to the variable english and the second to the variable german.\n",
        "\n",
        "We can combine this with a for-loop when we iterate over key/value pairs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-tUgRedt2aO",
        "outputId": "d06aa90f-7189-4a14-e485-a522d1abeec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hund is German for dog\n",
            "Katze is German for cat\n",
            "Guerteltier is German for armadillo\n"
          ]
        }
      ],
      "source": [
        "for english, german in mydict.items():\n",
        "    print(german, \"is German for\", english)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygc-2T8Ht2aO"
      },
      "source": [
        "The central line here is:\n",
        "```for english, german in mydict.items():```\n",
        "\n",
        "This is the same idea as above -- we know that any member of mydict.items() consists of two parts (a key and a value), so we can assign it to two variables at once.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj1Sa9xxt2aP"
      },
      "source": [
        "**Try it for yourself**:\n",
        "\n",
        "* Iterate through the key/value pairs in the ```nltk.FreqDist``` dictionary you made above from a passage you chose. For all words that consist solely of punctuation symbols, print out the words and counts.  \n",
        "\n",
        "* You can also iterate through the key/value pairs that you get from ``fd.most_common(20)``. For all words that don't consist solely of punctuation symbols, print the word and its count.\n",
        "\n",
        "\n",
        "A simple way to check for punctuation is to say  `not word.isalpha()` to check if `word` contains non-letter characters. But this will also get you words like \"say...\" since that contains non-letter characters. Here is a trick to check whether a word consists entirely of punctuation symbols:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LgoIvxnt2aP",
        "outputId": "ab8972b3-8264-46d3-eb1e-bcab340d8206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a string of all punctuation symbols that Python is aware of: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "this string consisted entirely of punctuation symbols.\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "print(\"Here is a string of all punctuation symbols that Python is aware of:\", string.punctuation)\n",
        "\n",
        "mystring = \"??!??\"\n",
        "if mystring.strip(string.punctuation) == \"\":\n",
        "    print(\"this string consisted entirely of punctuation symbols.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vefBgmm9t2aP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P_HGEqft2aP"
      },
      "source": [
        "* Using again the translation dictionary from above with animal names in English and German, iterate through key/value pairs, and for pairs where the German word is at least 7 letters long, print both the German word and its English translation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9j4zM7AAt2aP"
      },
      "outputs": [],
      "source": [
        "translationdict = {\"dog\":\"Hund\", \"cat\": \"Katze\",\n",
        "                   \"dormouse\":\"Siebenschlaefer\",\n",
        "                   \"praying mantis\":\"Gottesanbeterin\",\n",
        "                  \"gopher\" : \"Taschenratte\"}\n",
        "# put your code here.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-aQXPxTt2aP"
      },
      "source": [
        "# Dictionaries as attribute-value matrices\n",
        "\n",
        "The Universal Dependencies data represents each token (word) as an attribute-value matrix, stored as a dictionary. Here is the first word of the 10th sentence of the UD_English-GUM corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "q2NXW83Mt2aP"
      },
      "outputs": [],
      "source": [
        "firstword = {'id': 1,\n",
        "  'form': 'Thus',\n",
        "  'lemma': 'thus',\n",
        "  'upos': 'ADV',\n",
        "  'xpos': 'RB',\n",
        "  'feats': None,\n",
        "  'head': 16,\n",
        "  'deprel': 'advmod',\n",
        "  'deps': None,\n",
        "  'misc': {'SpaceAfter': 'No'}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sQSvPb_t2aP"
      },
      "source": [
        "This is the following attribute-value matrix (AVM):\n",
        "\n",
        "$$\n",
        "\\left[\\begin{array}{ll}\n",
        "\\text{id:} & 1\\\\\n",
        "\\text{form:} & 'Thus'\\\\\n",
        "\\text{lemma:} & 'thus'\\\\\n",
        "\\text{upos:} &  'ADV'\\\\\n",
        "\\text{xpos:} & 'RB'\\\\\n",
        "\\text{feats:} &  None\\\\\n",
        "\\text{head:} & 16\\\\\n",
        "\\text{deprel:}  & advmod\\\\\n",
        "\\text{deps:}  & None\\\\\n",
        "\\text{misc:} & \\left[\\begin{array}{ll}\n",
        "\\text{SpaceAfter:} & 'No'\n",
        "\\end{array}\\right]\n",
        "\\end{array}\\right]\n",
        "$$\n",
        "\n",
        "You can access an entry in this attribute-value matrix through its dictionary key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "iTmFGXArt2aP",
        "outputId": "abc9dd06-defc-4f0d-905d-28f5ae753965"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thus'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "firstword[\"lemma\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7WoSMJUt2aP"
      },
      "source": [
        "One of the values in the AVM is itself an AVM. To access the value that tells you whether there is a space after the word, you need to specify the whole path of keys. `firstword[\"misc\"]` accesses a dictionary, namely `{'SpaceAfter': 'No'}`, which again has keys, in particular `SpaceAfter`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "qiKxjIG9t2aP",
        "outputId": "1a27f534-c368-4b58-cb1e-5766cbe88d94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'No'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "firstword[\"misc\"][\"SpaceAfter\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSuwRTIUt2aP"
      },
      "source": [
        "The Universal Dependencies representation of a whole sentence is a list of tokens, that is, a list of dictionaries (=AVMs):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "ASSdKHqMt2aP"
      },
      "outputs": [],
      "source": [
        "sentence10 = [{'id': 1,\n",
        "  'form': 'Thus',\n",
        "  'lemma': 'thus',\n",
        "  'upos': 'ADV',\n",
        "  'xpos': 'RB',\n",
        "  'feats': None,\n",
        "  'head': 16,\n",
        "  'deprel': 'advmod',\n",
        "  'deps': None,\n",
        "  'misc': {'SpaceAfter': 'No'}},\n",
        " {'id': 2,\n",
        "  'form': ',',\n",
        "  'lemma': ',',\n",
        "  'upos': 'PUNCT',\n",
        "  'xpos': ',',\n",
        "  'feats': None,\n",
        "  'head': 1,\n",
        "  'deprel': 'punct',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 3,\n",
        "  'form': 'the',\n",
        "  'lemma': 'the',\n",
        "  'upos': 'DET',\n",
        "  'xpos': 'DT',\n",
        "  'feats': {'Definite': 'Def', 'PronType': 'Art'},\n",
        "  'head': 4,\n",
        "  'deprel': 'det',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 4,\n",
        "  'form': 'time',\n",
        "  'lemma': 'time',\n",
        "  'upos': 'NOUN',\n",
        "  'xpos': 'NN',\n",
        "  'feats': {'Number': 'Sing'},\n",
        "  'head': 16,\n",
        "  'deprel': 'nsubj',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 5,\n",
        "  'form': 'it',\n",
        "  'lemma': 'it',\n",
        "  'upos': 'PRON',\n",
        "  'xpos': 'PRP',\n",
        "  'feats': {'Case': 'Nom',\n",
        "   'Gender': 'Neut',\n",
        "   'Number': 'Sing',\n",
        "   'Person': '3',\n",
        "   'PronType': 'Prs'},\n",
        "  'head': 6,\n",
        "  'deprel': 'nsubj',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 6,\n",
        "  'form': 'takes',\n",
        "  'lemma': 'take',\n",
        "  'upos': 'VERB',\n",
        "  'xpos': 'VBZ',\n",
        "  'feats': {'Mood': 'Ind',\n",
        "   'Number': 'Sing',\n",
        "   'Person': '3',\n",
        "   'Tense': 'Pres',\n",
        "   'VerbForm': 'Fin'},\n",
        "  'head': 4,\n",
        "  'deprel': 'acl:relcl',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 7,\n",
        "  'form': 'and',\n",
        "  'lemma': 'and',\n",
        "  'upos': 'CCONJ',\n",
        "  'xpos': 'CC',\n",
        "  'feats': None,\n",
        "  'head': 9,\n",
        "  'deprel': 'cc',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 8,\n",
        "  'form': 'the',\n",
        "  'lemma': 'the',\n",
        "  'upos': 'DET',\n",
        "  'xpos': 'DT',\n",
        "  'feats': {'Definite': 'Def', 'PronType': 'Art'},\n",
        "  'head': 9,\n",
        "  'deprel': 'det',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 9,\n",
        "  'form': 'ways',\n",
        "  'lemma': 'way',\n",
        "  'upos': 'NOUN',\n",
        "  'xpos': 'NNS',\n",
        "  'feats': {'Number': 'Plur'},\n",
        "  'head': 4,\n",
        "  'deprel': 'conj',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 10,\n",
        "  'form': 'of',\n",
        "  'lemma': 'of',\n",
        "  'upos': 'SCONJ',\n",
        "  'xpos': 'IN',\n",
        "  'feats': None,\n",
        "  'head': 12,\n",
        "  'deprel': 'mark',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 11,\n",
        "  'form': 'visually',\n",
        "  'lemma': 'visually',\n",
        "  'upos': 'ADV',\n",
        "  'xpos': 'RB',\n",
        "  'feats': None,\n",
        "  'head': 12,\n",
        "  'deprel': 'advmod',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 12,\n",
        "  'form': 'exploring',\n",
        "  'lemma': 'explore',\n",
        "  'upos': 'VERB',\n",
        "  'xpos': 'VBG',\n",
        "  'feats': {'VerbForm': 'Ger'},\n",
        "  'head': 9,\n",
        "  'deprel': 'acl',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 13,\n",
        "  'form': 'an',\n",
        "  'lemma': 'a',\n",
        "  'upos': 'DET',\n",
        "  'xpos': 'DT',\n",
        "  'feats': {'Definite': 'Ind', 'PronType': 'Art'},\n",
        "  'head': 14,\n",
        "  'deprel': 'det',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 14,\n",
        "  'form': 'artwork',\n",
        "  'lemma': 'artwork',\n",
        "  'upos': 'NOUN',\n",
        "  'xpos': 'NN',\n",
        "  'feats': {'Number': 'Sing'},\n",
        "  'head': 12,\n",
        "  'deprel': 'obj',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 15,\n",
        "  'form': 'can',\n",
        "  'lemma': 'can',\n",
        "  'upos': 'AUX',\n",
        "  'xpos': 'MD',\n",
        "  'feats': {'VerbForm': 'Fin'},\n",
        "  'head': 16,\n",
        "  'deprel': 'aux',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 16,\n",
        "  'form': 'inform',\n",
        "  'lemma': 'inform',\n",
        "  'upos': 'VERB',\n",
        "  'xpos': 'VB',\n",
        "  'feats': {'VerbForm': 'Inf'},\n",
        "  'head': 0,\n",
        "  'deprel': 'root',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 17,\n",
        "  'form': 'about',\n",
        "  'lemma': 'about',\n",
        "  'upos': 'ADP',\n",
        "  'xpos': 'IN',\n",
        "  'feats': None,\n",
        "  'head': 19,\n",
        "  'deprel': 'case',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 18,\n",
        "  'form': 'its',\n",
        "  'lemma': 'its',\n",
        "  'upos': 'PRON',\n",
        "  'xpos': 'PRP$',\n",
        "  'feats': {'Gender': 'Neut',\n",
        "   'Number': 'Sing',\n",
        "   'Person': '3',\n",
        "   'Poss': 'Yes',\n",
        "   'PronType': 'Prs'},\n",
        "  'head': 19,\n",
        "  'deprel': 'nmod:poss',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 19,\n",
        "  'form': 'relevance',\n",
        "  'lemma': 'relevance',\n",
        "  'upos': 'NOUN',\n",
        "  'xpos': 'NN',\n",
        "  'feats': {'Number': 'Sing'},\n",
        "  'head': 16,\n",
        "  'deprel': 'obl',\n",
        "  'deps': None,\n",
        "  'misc': {'SpaceAfter': 'No'}},\n",
        " {'id': 20,\n",
        "  'form': ',',\n",
        "  'lemma': ',',\n",
        "  'upos': 'PUNCT',\n",
        "  'xpos': ',',\n",
        "  'feats': None,\n",
        "  'head': 21,\n",
        "  'deprel': 'punct',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 21,\n",
        "  'form': 'interestingness',\n",
        "  'lemma': 'interestingness',\n",
        "  'upos': 'NOUN',\n",
        "  'xpos': 'NN',\n",
        "  'feats': {'Number': 'Sing'},\n",
        "  'head': 19,\n",
        "  'deprel': 'conj',\n",
        "  'deps': None,\n",
        "  'misc': {'SpaceAfter': 'No'}},\n",
        " {'id': 22,\n",
        "  'form': ',',\n",
        "  'lemma': ',',\n",
        "  'upos': 'PUNCT',\n",
        "  'xpos': ',',\n",
        "  'feats': None,\n",
        "  'head': 27,\n",
        "  'deprel': 'punct',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 23,\n",
        "  'form': 'and',\n",
        "  'lemma': 'and',\n",
        "  'upos': 'CCONJ',\n",
        "  'xpos': 'CC',\n",
        "  'feats': None,\n",
        "  'head': 27,\n",
        "  'deprel': 'cc',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 24,\n",
        "  'form': 'even',\n",
        "  'lemma': 'even',\n",
        "  'upos': 'ADV',\n",
        "  'xpos': 'RB',\n",
        "  'feats': None,\n",
        "  'head': 27,\n",
        "  'deprel': 'advmod',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 25,\n",
        "  'form': 'its',\n",
        "  'lemma': 'its',\n",
        "  'upos': 'PRON',\n",
        "  'xpos': 'PRP$',\n",
        "  'feats': {'Gender': 'Neut',\n",
        "   'Number': 'Sing',\n",
        "   'Person': '3',\n",
        "   'Poss': 'Yes',\n",
        "   'PronType': 'Prs'},\n",
        "  'head': 27,\n",
        "  'deprel': 'nmod:poss',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 26,\n",
        "  'form': 'aesthetic',\n",
        "  'lemma': 'aesthetic',\n",
        "  'upos': 'ADJ',\n",
        "  'xpos': 'JJ',\n",
        "  'feats': {'Degree': 'Pos'},\n",
        "  'head': 27,\n",
        "  'deprel': 'amod',\n",
        "  'deps': None,\n",
        "  'misc': None},\n",
        " {'id': 27,\n",
        "  'form': 'appeal',\n",
        "  'lemma': 'appeal',\n",
        "  'upos': 'NOUN',\n",
        "  'xpos': 'NN',\n",
        "  'feats': {'Number': 'Sing'},\n",
        "  'head': 19,\n",
        "  'deprel': 'conj',\n",
        "  'deps': None,\n",
        "  'misc': {'SpaceAfter': 'No'}},\n",
        " {'id': 28,\n",
        "  'form': '.',\n",
        "  'lemma': '.',\n",
        "  'upos': 'PUNCT',\n",
        "  'xpos': '.',\n",
        "  'feats': None,\n",
        "  'head': 16,\n",
        "  'deprel': 'punct',\n",
        "  'deps': None,\n",
        "  'misc': None}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dyx8AMb6t2aQ",
        "outputId": "623b3116-cb56-402d-cd13-d27723bb58a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Thus ADV 16 advmod\n",
            "2 , PUNCT 1 punct\n",
            "3 the DET 4 det\n",
            "4 time NOUN 16 nsubj\n",
            "5 it PRON 6 nsubj\n",
            "6 takes VERB 4 acl:relcl\n",
            "7 and CCONJ 9 cc\n",
            "8 the DET 9 det\n",
            "9 ways NOUN 4 conj\n",
            "10 of SCONJ 12 mark\n",
            "11 visually ADV 12 advmod\n",
            "12 exploring VERB 9 acl\n",
            "13 an DET 14 det\n",
            "14 artwork NOUN 12 obj\n",
            "15 can AUX 16 aux\n",
            "16 inform VERB 0 root\n",
            "17 about ADP 19 case\n",
            "18 its PRON 19 nmod:poss\n",
            "19 relevance NOUN 16 obl\n",
            "20 , PUNCT 21 punct\n",
            "21 interestingness NOUN 19 conj\n",
            "22 , PUNCT 27 punct\n",
            "23 and CCONJ 27 cc\n",
            "24 even ADV 27 advmod\n",
            "25 its PRON 27 nmod:poss\n",
            "26 aesthetic ADJ 27 amod\n",
            "27 appeal NOUN 19 conj\n",
            "28 . PUNCT 16 punct\n"
          ]
        }
      ],
      "source": [
        "# now we can iterate through the AVMs for this sentence, and\n",
        "# print informati0n for each one\n",
        "for token in sentence10:\n",
        "    print(token[\"id\"], token[\"form\"], token[\"upos\"],\n",
        "          token[\"head\"], token[\"deprel\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h40IIcVpt2aQ"
      },
      "source": [
        "Now say we want to determine how often we have subject-verb-object (SVO) versus SOV versus VSO etc. in a Universal Dependencies corpus. To do that, we would like to have an AVM for a word that includes all its dependents. For the verb \"inform\" in the sentence above, we would like the AVM to list that \"time\" (word 4) is the nsubj of \"inform\", and \"relevance\" (word 19) is its obl:\n",
        "\n",
        "$$\n",
        "\\left[\\begin{array}{ll}\n",
        "\\text{form:} & inform\\\\\n",
        "\\text{id:} & 16\\\\\n",
        "\\text{upos:} & VERB\\\\\n",
        "\\text{dep:} & \\[ \\left[\\begin{array}{ll}\n",
        "\\text{id:} & 4\\\\\n",
        "\\text{deprel:} & nsubj\\end{array}\\right],\n",
        "\\left[\\begin{array}{ll}\n",
        "\\text{id:} & 19\\\\\n",
        "\\text{deprel:} & obl\\end{array}\\right]\\]\n",
        "\\end{array}\\right]\n",
        "$$\n",
        "\n",
        "As a Python data structure, this AVM is rather complex: It is a dictionary, but under the key \"dep\" the value is a list of dictionaries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "o4Pkssdbt2aQ"
      },
      "outputs": [],
      "source": [
        "inform_avm_with_deps = { \"form\" : \"inform\",\n",
        "                        \"id\" : 16,\n",
        "                        \"upos\" : \"VERB\",\n",
        "                        \"dep\" : [ {\"id\" : 4, \"deprel\" : \"nsubj\"},\n",
        "                                  {\"id\" : 19, \"deprel\" : \"obl\"}]\n",
        "                       }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60vKSZIqt2aQ"
      },
      "source": [
        "Here is how we make a version of sentence 10 that has such an AVM for each word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLIzYObat2aQ",
        "outputId": "b8890f7c-f119-4097-a1d7-ec0aca742929"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'form': 'Thus',\n",
              "  'id': 1,\n",
              "  'upos': 'ADV',\n",
              "  'dep': [{'id': 2, 'deprel': 'punct'}]},\n",
              " {'form': ',', 'id': 2, 'upos': 'PUNCT', 'dep': []},\n",
              " {'form': 'the', 'id': 3, 'upos': 'DET', 'dep': []},\n",
              " {'form': 'time',\n",
              "  'id': 4,\n",
              "  'upos': 'NOUN',\n",
              "  'dep': [{'id': 3, 'deprel': 'det'},\n",
              "   {'id': 6, 'deprel': 'acl:relcl'},\n",
              "   {'id': 9, 'deprel': 'conj'}]},\n",
              " {'form': 'it', 'id': 5, 'upos': 'PRON', 'dep': []},\n",
              " {'form': 'takes',\n",
              "  'id': 6,\n",
              "  'upos': 'VERB',\n",
              "  'dep': [{'id': 5, 'deprel': 'nsubj'}]},\n",
              " {'form': 'and', 'id': 7, 'upos': 'CCONJ', 'dep': []},\n",
              " {'form': 'the', 'id': 8, 'upos': 'DET', 'dep': []},\n",
              " {'form': 'ways',\n",
              "  'id': 9,\n",
              "  'upos': 'NOUN',\n",
              "  'dep': [{'id': 7, 'deprel': 'cc'},\n",
              "   {'id': 8, 'deprel': 'det'},\n",
              "   {'id': 12, 'deprel': 'acl'}]},\n",
              " {'form': 'of', 'id': 10, 'upos': 'SCONJ', 'dep': []},\n",
              " {'form': 'visually', 'id': 11, 'upos': 'ADV', 'dep': []},\n",
              " {'form': 'exploring',\n",
              "  'id': 12,\n",
              "  'upos': 'VERB',\n",
              "  'dep': [{'id': 10, 'deprel': 'mark'},\n",
              "   {'id': 11, 'deprel': 'advmod'},\n",
              "   {'id': 14, 'deprel': 'obj'}]},\n",
              " {'form': 'an', 'id': 13, 'upos': 'DET', 'dep': []},\n",
              " {'form': 'artwork',\n",
              "  'id': 14,\n",
              "  'upos': 'NOUN',\n",
              "  'dep': [{'id': 13, 'deprel': 'det'}]},\n",
              " {'form': 'can', 'id': 15, 'upos': 'AUX', 'dep': []},\n",
              " {'form': 'inform',\n",
              "  'id': 16,\n",
              "  'upos': 'VERB',\n",
              "  'dep': [{'id': 1, 'deprel': 'advmod'},\n",
              "   {'id': 4, 'deprel': 'nsubj'},\n",
              "   {'id': 15, 'deprel': 'aux'},\n",
              "   {'id': 19, 'deprel': 'obl'},\n",
              "   {'id': 28, 'deprel': 'punct'}]},\n",
              " {'form': 'about', 'id': 17, 'upos': 'ADP', 'dep': []},\n",
              " {'form': 'its', 'id': 18, 'upos': 'PRON', 'dep': []},\n",
              " {'form': 'relevance',\n",
              "  'id': 19,\n",
              "  'upos': 'NOUN',\n",
              "  'dep': [{'id': 17, 'deprel': 'case'},\n",
              "   {'id': 18, 'deprel': 'nmod:poss'},\n",
              "   {'id': 21, 'deprel': 'conj'},\n",
              "   {'id': 27, 'deprel': 'conj'}]},\n",
              " {'form': ',', 'id': 20, 'upos': 'PUNCT', 'dep': []},\n",
              " {'form': 'interestingness',\n",
              "  'id': 21,\n",
              "  'upos': 'NOUN',\n",
              "  'dep': [{'id': 20, 'deprel': 'punct'}]},\n",
              " {'form': ',', 'id': 22, 'upos': 'PUNCT', 'dep': []},\n",
              " {'form': 'and', 'id': 23, 'upos': 'CCONJ', 'dep': []},\n",
              " {'form': 'even', 'id': 24, 'upos': 'ADV', 'dep': []},\n",
              " {'form': 'its', 'id': 25, 'upos': 'PRON', 'dep': []},\n",
              " {'form': 'aesthetic', 'id': 26, 'upos': 'ADJ', 'dep': []},\n",
              " {'form': 'appeal',\n",
              "  'id': 27,\n",
              "  'upos': 'NOUN',\n",
              "  'dep': [{'id': 22, 'deprel': 'punct'},\n",
              "   {'id': 23, 'deprel': 'cc'},\n",
              "   {'id': 24, 'deprel': 'advmod'},\n",
              "   {'id': 25, 'deprel': 'nmod:poss'},\n",
              "   {'id': 26, 'deprel': 'amod'}]},\n",
              " {'form': '.',\n",
              "  'id': 28,\n",
              "  'upos': 'PUNCT',\n",
              "  'dep': [{'id': 16, 'deprel': 'root'}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "# first we initialize each AVM to have an empty dependencies list\n",
        "sentence10_reformat = [ ]\n",
        "for token in sentence10:\n",
        "    sentence10_reformat.append( { \"form\" : token[\"form\"],\n",
        "                                  \"id\" : token[\"id\"],\n",
        "                                  \"upos\" : token[\"upos\"],\n",
        "                                  \"dep\" : [ ]\n",
        "                                } )\n",
        "\n",
        "# now we add dependencies\n",
        "for token in sentence10:\n",
        "    # looking up the head of this token. index is that head minus one.\n",
        "    myhead_ix = token[\"head\"] - 1\n",
        "    # print(token[\"form\"], token[\"id\"], token[\"head\"], sentence10_reformat[myhead_ix][\"form\"])\n",
        "    # adding this token to the head's dependencies\n",
        "    sentence10_reformat[ myhead_ix ][\"dep\"].append({ \"id\" : token[\"id\"],\n",
        "                                                     \"deprel\" : token[\"deprel\"]})\n",
        "\n",
        "sentence10_reformat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ-N1CBCt2aQ"
      },
      "source": [
        "Based on this data structure, we can determine whether the subject is before the verb: If so, its ID is lower than that of the verb. We can also determine whether the subject is before the object: If so, its ID isd lower than that of the the object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUdQLMfNt2aR"
      },
      "source": [
        "# Counting words to get a sense of topic\n",
        "\n",
        "Here is a more complex counting task: In a text, we count how often words appear, to get a sense of the topic of the text.\n",
        "\n",
        "**Try it for yourself:** All the problems below are for you to solve.\n",
        "\n",
        "## Words across all State of the Union addresses\n",
        "\n",
        "We'll first do word counts across *all* state of the union addresses. Like in the previous notebook, we'll use NLTK's interface to the speeches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6Ghxnzbt2aR",
        "outputId": "5dcd1581-8cf8-42ee-902b-3a8bcb0dd0cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/state_union.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "# making sure we have all we need\n",
        "import nltk\n",
        "nltk.download('state_union')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_blDL8_wt2aR"
      },
      "source": [
        "We'll need an aggregator variable to collect word counts across all state of the union addresses. This time, our aggregator variable will be a sheet of counts, specifically an NLTK FreqDist. Since we count words across all speeches, we use one single FreqDist to collect counts.\n",
        "\n",
        "Here is a neat fact about NLTK's FreqDist objects: You can use the method `update()` to add a whole new list of words to the counts, like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFjvd_Wot2aR",
        "outputId": "cc30345b-0b18-4c81-99c2-693e5b3b8641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_items([('here', 1), ('are', 1), ('some', 1), ('words', 1)]) \n",
            "\n",
            "dict_items([('here', 2), ('are', 2), ('some', 1), ('words', 2), ('more', 1)])\n"
          ]
        }
      ],
      "source": [
        "fd = nltk.FreqDist([\"here\", \"are\", \"some\", \"words\"])\n",
        "print(fd.items(), \"\\n\")\n",
        "# here comes the trick\n",
        "fd.update([\"here\", \"are\", \"more\", \"words\"])\n",
        "print(fd.items())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYLqCMZ1t2aR"
      },
      "source": [
        "Here is an example of a FreqDist as an aggregator variable. It counts words in ae Edward Lear poem, one line at a time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV23HLOTt2aR",
        "outputId": "345910da-4be8-4c9c-a928-6f66cbdd5677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I got this many lines: 13\n",
            "[('a', 9), ('to', 5), ('Sieve', 5), ('went', 4), ('they', 4), ('In', 4), ('and', 4), ('And', 3), ('the', 3), ('They', 2)]\n"
          ]
        }
      ],
      "source": [
        "# first stanza of a poem by Edward Lear,\n",
        "# one string per line\n",
        "data = [\n",
        "\"They went to sea in a Sieve, they did\",\n",
        "\"In a Sieve they went to sea:\",\n",
        "\"In spite of all their friends could say,\"\n",
        "\"On a winter's morn, on a stormy day,\",\n",
        "\"In a Sieve they went to sea!\",\n",
        "\"And when the Sieve turned round and round,\",\n",
        "\"And every one cried, `You'll all be drowned!'\",\n",
        "\"They called aloud, `Our Sieve ain't big,\",\n",
        "\"But we don't care a button! we don't care a fig!\",\n",
        "\"In a Sieve we'll go to sea!'\",\n",
        "\"Far and few, far and few,\",\n",
        "\"Are the lands where the Jumblies live;\",\n",
        "\"Their heads are green, and their hands are blue,\",\n",
        "\"And they went to sea in a Sieve.\"]\n",
        "\n",
        "print(\"I got this many lines:\", len(data))\n",
        "\n",
        "# aggregator variable\n",
        "fd = nltk.FreqDist()\n",
        "# loop\n",
        "for line in data:\n",
        "    words = line.split()\n",
        "    # adding to the aggregator variable\n",
        "    fd.update(words)\n",
        "\n",
        "print(fd.most_common(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "552bbdoLt2aR"
      },
      "source": [
        "Now do the following:\n",
        "* Make a FreqDist object as your aggregator variable\n",
        "* iterate over fileIDs of state of the union addresses, as in the previous notebook\n",
        "* for each fileID:\n",
        "  * pull up the speech, as a list of words\n",
        "  * add it to the aggregator variable\n",
        "  \n",
        "What are the most frequent words?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZZCY4aTt2aR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClqGckN6t2aR"
      },
      "source": [
        "You'll see a lot of \"uninteresting\" words come out on top. To make them disappear, let's remove \"stopwords\" from each speech. You can get NLTK's English stopwords like this -- I'm only showing the first 10:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EepR3m9t2aS",
        "outputId": "b807bb1e-3ea2-4275-8536-47433bec77c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "nltk.corpus.stopwords.words(\"english\")[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKKo9Re2t2aS"
      },
      "source": [
        "In a single state of the union address, you can remove stopwords like this:\n",
        "\n",
        "* for each word of the speech:\n",
        "  * if it is not in the list of stopwords:\n",
        "    * add it to the sheet of counts\n",
        "    \n",
        "Let's do this for the first state of the union address:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WImBdZ3Ut2aS",
        "outputId": "5707264a-3b3c-4070-b2ac-de17298e450f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.', 105),\n",
              " (',', 92),\n",
              " ('peace', 23),\n",
              " ('world', 20),\n",
              " ('must', 20),\n",
              " ('I', 17),\n",
              " ('We', 17),\n",
              " ('-', 16),\n",
              " ('!', 12),\n",
              " ('America', 11),\n",
              " ('The', 10),\n",
              " ('people', 10),\n",
              " ('nations', 10),\n",
              " ('In', 8),\n",
              " ('hope', 8),\n",
              " ('freedom', 7),\n",
              " ('never', 7),\n",
              " ('great', 6),\n",
              " ('upon', 6),\n",
              " ('shall', 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "sotu_fileids = nltk.corpus.state_union.fileids()\n",
        "first_fileid = sotu_fileids[0]\n",
        "first_sotu = nltk.corpus.state_union.words(fileids = first_fileid)\n",
        "\n",
        "mystopwords= nltk.corpus.stopwords.words(\"english\")\n",
        "\n",
        "fd = nltk.FreqDist()\n",
        "for word in first_sotu:\n",
        "    if word not in mystopwords:\n",
        "        fd[word] += 1\n",
        "\n",
        "fd.most_common(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG1lV_dmt2aS"
      },
      "source": [
        "To do this for all state of the union addresses,\n",
        "* you make an outer loop that iterates over all speeches, vias their file IDs.\n",
        "* then for each speech, loop over all the words in that speech.\n",
        "* if the current word is not a stopword, add it to our sheet of counts.\n",
        "  \n",
        "Let's do this, and then see if we get better words coming out on top:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CabpzYtDt2aS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}