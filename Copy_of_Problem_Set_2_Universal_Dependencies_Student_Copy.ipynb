{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Teaganstmp/Langlearning/blob/main/Copy_of_Problem_Set_2_Universal_Dependencies_Student_Copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Dependency Lengths with the Universal Dependencies Corpus\n",
        "\n",
        "In this advanced option for the problem set, you are going to explore the Universal Dependencies corpus in order to study **dependency lengths**, a feature of language that has been shown to have many psycholinguistically important properties.\n",
        "\n",
        "A dependency (as you know from our work so far with the UD corpus) is a structural relationship between semantically connected words that does not necessarily depend on the linear distance between those words. It has been argued that dependencies are minimized in language and that this can explain certain preferences. For instance, you can say:\n",
        "\n",
        "(1) \"I threw the trash out\"\n",
        "\n",
        "or\n",
        "\n",
        "(2) \"I threw out the trash\"\n",
        "\n",
        "In these sentences (which speakers seem to find equally good), there is a dependency relationship between \"threw\" and \"out\".\n",
        "\n",
        "But many English speakers have a preference for (3) over (4):\n",
        "\n",
        "(3) \"I threw out the trash that was sitting on the porch and beginning to smell.\"\n",
        "\n",
        "(4) \"I threw the trash that was sitting on the porch and beginning to smell out.\"\n",
        "\n",
        "The claim is that (4) is dispreferred because of the very long dependency between \"threw\" and \"out\".\n",
        "\n",
        "See Futrell, Mahowald, Gibson (2015) https://mahowak.github.io/assets/pdf/dep.pdf, which used the Universal Dependencies corpus. In this paper, we operationalize dependency lengths in a simple way: the number of words from a head to its dependent. So for \"I threw out the trash\", the dependency distance between \"threw\" and \"out\" is 1. In \"I threw the trash out\", the distance between \"threw\" and \"out\" is 3.\n",
        "\n",
        "We want you to explore some questions related to this topic below, using the Universal Dependencies corpus to assess whether dependency relationships are minimized in human languages.\n",
        "\n",
        "Show all your code here, and include nice comments and explanatory text. When there are questions we ask you to answer in prose, use the text box instead of the code box."
      ],
      "metadata": {
        "id": "s0rbAttt-vo7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some code to get going with the UD Corpus"
      ],
      "metadata": {
        "id": "xjXv0ceHgcOO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d63qpRupjmUC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c6a8c7-7532-4448-cac4-1d6cfaa62737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting conllu\n",
            "  Downloading conllu-5.0.1-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading conllu-5.0.1-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-5.0.1\n",
            "--2024-09-01 23:14:34--  https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz\n",
            "Resolving lindat.mff.cuni.cz (lindat.mff.cuni.cz)... 195.113.20.140\n",
            "Connecting to lindat.mff.cuni.cz (lindat.mff.cuni.cz)|195.113.20.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 355216681 (339M) [application/x-gzip]\n",
            "Saving to: ‘ud-treebanks-v2.5.tgz’\n",
            "\n",
            "ud-treebanks-v2.5.t 100%[===================>] 338.76M  21.4MB/s    in 18s     \n",
            "\n",
            "2024-09-01 23:14:54 (18.4 MB/s) - ‘ud-treebanks-v2.5.tgz’ saved [355216681/355216681]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Code and text from https://colab.research.google.com/drive/1d7LO_0665DYw6DrVJXXautJAJzHHqYOm#scrollTo=4WwZYkNr1bPN\n",
        "#This cell loads the Universal Dependecies Treekbank corpus. It'll download all the packages, but we'll only use the GUM\n",
        "#english package. We'll also install the conllu package, that was developed to parse data in the conLLu format, a\n",
        "#format common of linguistic annotated files. We'll also have a list variable, but now named ud_treebank.\n",
        "\n",
        "#Install conllu package, download the UD Treebanks corpus and unpack it.\n",
        "!pip install conllu\n",
        "!wget https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz\n",
        "!tar zxf ud-treebanks-v2.5.tgz\n",
        "\n",
        "#The imports needed to open and parse the conllu file. At the end we'll have a list of dicts.\n",
        "from io import open\n",
        "import conllu\n",
        "import glob\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# this code gets all the languages\n",
        "ud_files = glob.glob(\"ud-treebanks-v2.5/*/*-test.conllu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 1: our first analysis of dependency lengths\n",
        "\n",
        "Your task is to, for each language in `ud_files` above, find the average dependency length of all the dependencies in that language, across the entire corpus.\n",
        "\n",
        "So for \"The dog ran\", you'll find a dependency of length 1 between \"the\" and \"dog\", a dependency of length \"1\" between \"dog\" and \"ran\". So the average is 1. For our purposes, you can compute a dependency length by just subtracting the head ID from the dependent ID and taking the absolute value `abs()` since we don't want to deal with negative dependency lengths: we care about the distance.\n",
        "\n",
        "There are likely some choices you will have to make in how to do this: there is no one right way to do it, but we encourage you to document and validate your choices. (Think especially carefully about choices that could affect the linguistic conclusions you draw. N.B.: how do you think dependency lengths relate to sentence lengths?)\n",
        "\n",
        "Below, we guide you through how to get started."
      ],
      "metadata": {
        "id": "uErDrmmBhEb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 1a\n",
        "\n",
        "To get you started, here is some starter code looking at one English sentence from the GUM corpus: \"He was interviewed by Wikinews.\"\n",
        "\n",
        "To play around with that sentence, here is some code to put it into a nicer format `nicedata'. You can use this format for your own analyses.\n",
        "\n",
        "Play around with this code to get a sense of what it does."
      ],
      "metadata": {
        "id": "sV99dIRmO_dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some starter code to explore one sentence and put it in a nice format\n",
        "# you will want to get this into a function\n",
        "file_path = \"ud-treebanks-v2.5/UD_English-GUM/en_gum-ud-train.conllu\"\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "  data = f.read()\n",
        "\n",
        "# Parse the file using the conllu library\n",
        "sentences = conllu.parse(data)\n",
        "s = sentences[1991]\n",
        "print(s) # Our sentence is: \"He was interviewed by Wikinews.\"\n",
        "nicedata = [{\"token\": None,\n",
        "             \"id\": i,\n",
        "             \"deps\": [],\n",
        "             \"pos\": None}\n",
        "            for i in range(len(s) + 1)]\n",
        "for token in s:\n",
        "    if token[\"head\"] is not None and token[\"id\"] != 0: # we need to be careful here!\n",
        "      nicedata[token[\"id\"]][\"token\"] = token[\"form\"]\n",
        "      nicedata[token[\"id\"]][\"pos\"] = token[\"upos\"]\n",
        "      nicedata[token[\"head\"]][\"deps\"] += [(token[\"id\"], token[\"deprel\"])]\n",
        "\n",
        "for token in nicedata:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKE73um4yFS2",
        "outputId": "890506cd-079a-411a-a751-da6b9b430ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TokenList<He, was, interviewed, by, Wikinews, ., metadata={sent_id: \"GUM_interview_shalev-6\", text: \"He was interviewed by Wikinews.\", s_type: \"decl\"}>\n",
            "{'token': None, 'id': 0, 'deps': [(3, 'root')], 'pos': None}\n",
            "{'token': 'He', 'id': 1, 'deps': [], 'pos': 'PRON'}\n",
            "{'token': 'was', 'id': 2, 'deps': [], 'pos': 'AUX'}\n",
            "{'token': 'interviewed', 'id': 3, 'deps': [(1, 'nsubj:pass'), (2, 'aux:pass'), (5, 'obl'), (6, 'punct')], 'pos': 'VERB'}\n",
            "{'token': 'by', 'id': 4, 'deps': [], 'pos': 'ADP'}\n",
            "{'token': 'Wikinews', 'id': 5, 'deps': [(4, 'case')], 'pos': 'PROPN'}\n",
            "{'token': '.', 'id': 6, 'deps': [], 'pos': 'PUNCT'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above we see the dependencies in our `nicedata` structure. It seems like we probably shouln't count the 0th element (which points to \"root\") or the punctuation. Why is that?\n",
        "\n",
        "So what we do want to count are these dependencies:\n",
        "- interviewed (3) to he (1)\n",
        "- interviewed (3) to was (2)\n",
        "- interviewed (3) to Wikinews (5)\n",
        "- Wikinews (5) to by (4)\n",
        "\n",
        "Computing this manually, we should get dependency lengths of [2, 1, 2, 1] for a mean of 1.5. Write code to do this by processing `nicedata`.\n",
        "\n",
        "Confirm that for this sentence you get a length of 1.5.\n"
      ],
      "metadata": {
        "id": "5s6bl68v-PP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "\n",
        "# a nice thing to do when coding is to use unit tests\n",
        "# to make sure things are working as expected\n",
        "# if deplengths is your list of dependency lengths for the sentence\n",
        "# the below code will check that the mean is equal to 1.5\n",
        "mean_deplengths = np.mean(deplengths)\n",
        "assert(mean_deplengths == 1.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjQU-xq2JVNh",
        "outputId": "3af17ecb-27de-400a-ea51-0347704b6b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1b\n",
        "\n",
        "Using the steps above as you see fit, now actually compute the dependency lengths, across all dependences in each corpus.\n",
        "\n",
        "Dependency lengths are confounded with sentence length: a sentence of length 5 can't have a dependency length of 100! To get around this, you might choose to filter your data to look at only sentences of the same length (length 10 might be a good length to pick).\n",
        "\n",
        "You should print out the name of the language + its corpus information (so you will have multiple Englishes, for instance) along with its average dependency length. To get a nice average over a list, rounded to two decimals you can use `round(np.mean(LIST), 2)` where LIST is the name of your list of dependency lengths."
      ],
      "metadata": {
        "id": "v5bpTwZqPfly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_nice_data(fn):\n",
        "  \"\"\"TODO: write a function which takes in the filename from the list in ud_files,\n",
        "  return a dictionary with the nicedata format and a language\"\"\"\n",
        "  return {\"lang\": lang, \"nicedata\": nicesents}\n",
        "\n",
        "\n",
        "# TODO: run get_nice_data() to get all the languages in a nicer format"
      ],
      "metadata": {
        "id": "ZVWqHSfMBuI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dep_lengths(nicedata):\n",
        "  \"\"\"TODO: compute the dependency lengths on nice data,\n",
        "  return the list of dependency lengths\"\"\"\n",
        "  return deplengths\n",
        "\n",
        "# TODO: compute the average dependency length for each language"
      ],
      "metadata": {
        "id": "SpXB8VilpSPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2\n",
        "\n",
        "Now we want to start tackling the problem of whether dependency relations are minimized. But how do we do this? So, ok, let's say the average dependency length in English is 6.7 or whatever. Is that a lot? A little? We need to compare to something!\n",
        "\n",
        "What should we compare to? Let's try something simple: a random baseline. Instead of computing the dependency lengths as they really are, let's compare them to a random baseline.\n",
        "\n",
        "To do this, take all the sentences as you have them and create a new `id` for each token called `random_id` which randomly pairs an id with each token.\n",
        "\n",
        "So if you have:\n",
        "The id: 1\n",
        "dog id: 2\n",
        "chased id: 3\n",
        "the id: 4\n",
        "cat id: 5\n",
        "\n",
        "It might become:\n",
        "The id: 1 random_id: 4\n",
        "dog id: 2 random_id: 3\n",
        "chased id: 3 random_id: 1\n",
        "the id: 4 random_id: 5\n",
        "cat id: 5 random_id: 2\n",
        "\n",
        "Now do your analyses from Problem 1 (note that you should create functions in Problem 1 that you can re-use!) for both `id` and `random_id`. Get the average dependency length for each language, using `id` and `random_id`.\n",
        "\n",
        "We walk through how to do that below."
      ],
      "metadata": {
        "id": "wRYAqTdzirao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2a\n",
        "\n",
        "To get started, let's play around with a nice way to do the random baseline by permuting the ids. Your task is to compute the dependency lengths using our new order, assuming that the dependency structure is the SAME as with the old order (so there is still a dependency between \"wikinews\" and \"by\", for instance).\n",
        "\n",
        "Below we take our same sentence: \"He was interviewed by Wikinews.\"\n",
        "and change it to  \"was he by . interviewed Wikinews\"\n",
        "\n",
        "We still keep the dependents and heads the same, but they have a new order. So we get new dep lengths:\n",
        "- interviewed (5) to he (2)\n",
        "- interviewed (5) to was (1)\n",
        "- interviewed (5) to Wikinews (6)\n",
        "- Wikinews (6) to by (3)\n",
        "\n",
        "Averaging these together we get [3, 4, 2, 3] for a mean of 2.75.\n",
        "\n",
        "Below, write some code to compute the dependency lengths and make sure that you get 3.\n",
        "\n"
      ],
      "metadata": {
        "id": "iz4aIZVkQdf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"ud-treebanks-v2.5/UD_English-GUM/en_gum-ud-train.conllu\"\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "  data = f.read()\n",
        "\n",
        "# Parse the file using the conllu library\n",
        "sentences = conllu.parse(data)\n",
        "s = sentences[1991]\n",
        "print(s) # Our sentence is: \"He was interviewed by Wikinews.\"\n",
        "nicedata = [{\"token\": None, \"id\": i, \"deps\": [], \"pos\": None} for i in range(len(s) + 1)]\n",
        "for token in s:\n",
        "    if token[\"head\"] is not None and token[\"id\"] != 0: # we need to be careful here!\n",
        "      nicedata[token[\"id\"]][\"token\"] = token[\"form\"]\n",
        "      nicedata[token[\"id\"]][\"pos\"] = token[\"upos\"]\n",
        "      nicedata[token[\"head\"]][\"deps\"] += [(token[\"id\"], token[\"deprel\"])]\n",
        "\n",
        "# let's assume now that we have some random order\n",
        "# \"he was interviewed by wikinews .\" > \"was he by . interviewed Wikinews\"\n",
        "# so we can learn a mapping from the old index to the random index (keeping 0\n",
        "# the same)\n",
        "mapping_from_old_to_rand = {0: 0,\n",
        "                   1: 2,\n",
        "                   2: 1,\n",
        "                   3: 5,\n",
        "                   4: 3,\n",
        "                   5: 6,\n",
        "                   6: 4}\n",
        "rev_map = {mapping_from_old_to_rand[i]: i for i in mapping_from_old_to_rand}\n",
        "\n",
        "# print the new order\n",
        "for i in range(len(nicedata)):\n",
        "  print(nicedata[rev_map[i]][\"token\"])\n",
        "\n",
        "# TODO: get the dependency lengths for the new sentence\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7kNXIIzLHIY",
        "outputId": "a4a30dbd-2885-42eb-f300-9de726a09750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TokenList<He, was, interviewed, by, Wikinews, ., metadata={sent_id: \"GUM_interview_shalev-6\", text: \"He was interviewed by Wikinews.\", s_type: \"decl\"}>\n",
            "None\n",
            "was\n",
            "He\n",
            "by\n",
            ".\n",
            "interviewed\n",
            "Wikinews\n",
            "2 5\n",
            "1 5\n",
            "6 5\n",
            "3 6\n",
            "[3, 4, 1, 3]\n",
            "2.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, you can see how to do this for a different random order each time. Run the code below a few times to see the different random orders that emerge. Note that we keep the 0th position the same so that we don't mess with the root."
      ],
      "metadata": {
        "id": "cJEZaVOCQvvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we can make a new random order, keeping the 0th position constant\n",
        "randlist = [0] + random.sample(range(1, len(nicedata)), len(nicedata) - 1)\n",
        "mapping_from_old_to_rand = {i: randlist[i] for i in range(len(randlist))}\n",
        "rev_map = {mapping_from_old_to_rand[i]: i for i in mapping_from_old_to_rand}\n",
        "\n",
        "# print the new order\n",
        "print(\" \".join([nicedata[rev_map[i]][\"token\"] for i in range(1, len(nicedata))]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dkxa6BJbQvCS",
        "outputId": "eac2462a-b74b-4c9b-c804-00b3cd0a9a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "interviewed . was He Wikinews by\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2b\n",
        "\n",
        "Now actually compute the average dependency for each language, comparing it to its random baseline! Feel free to use the code above, and set a new random order per sentence.\n",
        "\n",
        "For how many langauges, is the mean dependency length for `id` longer than for `random_id`? Print the result and also include some text discussing this.\n",
        "\n",
        "Are random dependency lengths longer or shorter than real language dependency lengths?\n",
        "\n",
        "Bonus: Why isn't this an ideal random baseline? You can refer to the 2015 paper linked above to get some ideas for other baselines!\n",
        "\n",
        "Bonus 2: Outline a procedure for helping us be confident that these results mean what we think. You might consider things like statistical significance, robustness to the choices you made in your analysis, and more."
      ],
      "metadata": {
        "id": "ll0SZh_6Qlxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: compare the real dependency lenghts to the random baseline!"
      ],
      "metadata": {
        "id": "8MuLoVx_iqb5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}